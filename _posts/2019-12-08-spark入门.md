### 启动单机spark
- spark-shell
- pyshpark
- /opt/spark-2.4.4-bin-hadoop2.7/sbin/start-master.sh 启动主节点
- /opt/spark-2.4.4-bin-hadoop2.7/sbin/start-slave.sh spark://7576cf9c687e:7077 启动从节点
- jps 查看启动服务
- MASTER=spark://7576cf9c687e:7077 spark-shell 启动Apllication
- /opt/spark-2.4.4-bin-hadoop2.7/sbin/stop-all.sh 停止所有服务
- spark-shell --master spark://7576cf9c687e:7077  --jars code.jar    让 Spark Shell 中可以使用某些 jar 模块
- spark-shell --master spark://7576cf9c687e:7077 --packages "org.example:example:0.1"   通过 maven 坐标来引用一个依赖

### 启动spark集群
上面的步骤介绍了我们在单机模式Standalone Mode下部署的 Spark 环境，如果要部署 Spark 集群稍有区别：
1. 主节点上配置 spark ，例如 conf/spark-env.sh 中的环境变量
2. 主节点上配置 conf/slaves ，添加从节点的主机名，注意需要先把所有主机名输入到 /etc/hosts 避免无法解析
3. 把配置好的 spark 目录拷贝到所有从节点，从节点上的目录路径与主节点一致，例如都设置为/opt/spark-2.3.1-bin-hadoop2.6
4. 配置主节点到所有从节点的 SSH 无密码登录，使用ssh-keygen -t rsa和ssh-copy-id两个命令
5. 启动 spark 集群，在主节点上执行sbin/start-all.sh
6. 进入主节点的 web 界面查看所有 worker 是否成功启动

### RDD
- 
